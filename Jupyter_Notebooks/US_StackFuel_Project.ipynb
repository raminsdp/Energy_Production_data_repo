{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445dc929-a1f0-44f2-98b7-95d129d1f08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "#os.listdir()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756d917e-725f-4768-8a2d-4dc7e44988fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, zipfile\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "\n",
    "# Stations id's per Bundesland bekommen\n",
    "url = 'https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/daily/solar/ST_Tageswerte_Beschreibung_Stationen.txt'\n",
    "\n",
    "df_dwd = pd.read_fwf(url,encoding = \"ISO-8859-1\",colspecs=[(0,5),(6,14),(15,23),(36,38),(43,51),(53,60),(61,84),(142,165)])[1:]\n",
    "df_dwd.columns = ['Stations_id', 'von_datum', 'bis_datum', 'Stationshoehe', 'geoBreite', 'geoLaenge', 'Stationsname', 'Bundesland']\n",
    "mask = (df_dwd.loc[:,'Bundesland'] == 'Bayern') & (df_dwd.loc[:,'von_datum'] < '20150101') & (df_dwd.loc[:,'bis_datum'] >= '20231231')\n",
    "stations = list(df_dwd.loc[mask,'Stations_id'])\n",
    "\n",
    "# creating empty Dataframe\n",
    "df_stations = pd.DataFrame({'date': pd.date_range(start='1/1/2023', freq='1d', periods=365)})\n",
    "\n",
    "# Datenzusammenstellung\n",
    "for station in stations:\n",
    "    req = requests.get('https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/daily/solar/tageswerte_ST_'+station+'_row.zip')\n",
    "    zip = zipfile.ZipFile(BytesIO(req.content))  \n",
    "    f = zip.open(zip.namelist()[-1])\n",
    "    content = f.read()\n",
    "    s=str(content,'utf-8')\n",
    "    data = StringIO(s) \n",
    "    df_stat = pd.read_csv(data,sep=';',parse_dates=['MESS_DATUM'],usecols=['MESS_DATUM','FD_STRAHL','FG_STRAHL','SD_STRAHL'])\n",
    "    mask = (df_stat.loc[:,'MESS_DATUM'] >= '2023-01-01') & (df_stat.loc[:,'MESS_DATUM'] <= '2023-12-31')\n",
    "    df_stat.columns =['date',station+'_FD_STRAHL',station+'_FG_STRAHL',station+'_SD_STRAHL']\n",
    "    df_stations = df_stations.merge(df_stat.loc[mask,:],on='date')\n",
    "\n",
    "\n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f77f12-4a76-41e1-949a-51f8b687c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999713b3-9478-4cc6-8726-e77e2e8a9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source: https://opendata.dwd.de/climate_environment/CDC/observations_germany/climate/daily/solar/\n",
    "# several stations for BY are missing\n",
    "\n",
    "df = pd.DataFrame({'date': pd.date_range(start='1/1/2023', freq='1d', periods=365)})\n",
    "\n",
    "stationsid = ['03668','05792']\n",
    "for id in stationsid:\n",
    "    stationsname = 'Station_'+id+'.txt'\n",
    "    df_stat = pd.read_csv(stationsname,sep=';',parse_dates=['MESS_DATUM'],usecols=['MESS_DATUM','FD_STRAHL','FG_STRAHL','SD_STRAHL'])\n",
    "    mask = (df_stat.loc[:,'MESS_DATUM'] >= '2023-01-01') & (df_stat.loc[:,'MESS_DATUM'] <= '2023-12-31')\n",
    "    df_stat.columns =['date',id+'_FD_STRAHL',id+'_FG_STRAHL',id+'_SD_STRAHL']\n",
    "    df = df.merge(df_stat.loc[mask,:],on='date')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c43aef-8e26-4be6-9ade-b9d4e338f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source: https://netztransparenz.tennet.eu/de/strommarkt/transparenz/transparenz-deutschland/netzkennzahlen/tatsaechliche-und-prognostizierte-solarenergieeinspeisung/bayern/\n",
    "# filtered for 2023-01-01 to 2023-12-31\n",
    "\n",
    "df_en_raw = pd.read_table('solarEnergyFeedIn_BY_2023-01-01_2023-12-31.csv',sep=';',parse_dates=['Datum'],decimal=',')\n",
    "\n",
    "df_en = pd.DataFrame({'date': pd.date_range(start='1/1/2023', freq='1d', periods=365)})\n",
    "df_en.loc[:,'Prog_in_MW'] = pd.DataFrame(df_en_raw.groupby(['Datum'], as_index=False)['Prognostiziert in MW'].sum()).iloc[:,1]\n",
    "df_en.loc[:,'Act_in_MW'] = pd.DataFrame(df_en_raw.groupby(['Datum'], as_index=False)['Tatsaechlich in MW'].sum()).iloc[:,1]\n",
    "df = df.merge(df_en,on='date')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd43dd3-1533-4f42-942e-2d8d8311a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = open(\"Einheitensolar/EinheitenSolar_38.xml\", \"r\")\n",
    "#print(file.read()[:3500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c330f6-eb0d-42e4-8806-b501c7d41d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source: https://download.marktstammdatenregister.de/Gesamtdatenexport_20240306_23.2.zip\n",
    "# files: EinheitenSolar_1-39.xml\n",
    "\n",
    "#import xml.etree.ElementTree as ET\n",
    "#\n",
    "#files = list(range(1,40))\n",
    "#df_mod_raw = pd.DataFrame(columns=['Datum', 'PLZ', 'Bruttoleistung','Nettonennleistung','Inbetriebnahme'])\n",
    "#counter = 0\n",
    "#for file in files:\n",
    "#    source = 'data/EinheitenSolar_'+str(file)+'.xml'\n",
    "#    tree = ET.parse(source)\n",
    "#    root = tree.getroot()\n",
    "#    \n",
    "#    for einheit in root.findall('EinheitSolar'):\n",
    "#        try: \n",
    "#            land = einheit.find('Bundesland').text\n",
    "#        except:\n",
    "#            land = 'Unbekannt'\n",
    "#        if land == '1403': # Bundesland 1403 = Bayern\n",
    "#            try: \n",
    "#                inbetrieb = einheit.find('Inbetriebnahmedatum').text\n",
    "#            except:\n",
    "#                inbetrieb = 'Ausser_Betrieb'\n",
    "#            \n",
    "#            if inbetrieb.startswith('2023'):  \n",
    "#                plz = einheit.find('Postleitzahl').text \n",
    "#                brutto = float(einheit.find('Bruttoleistung').text)\n",
    "#                netto = float(einheit.find('Nettonennleistung').text)\n",
    "#                datum = einheit.find('DatumLetzteAktualisierung').text\n",
    "#        \n",
    "#                datum = datum[:10]\n",
    "#                df_mod_raw.loc[counter] = [datum,plz,brutto,netto,inbetrieb]\n",
    "#                counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b52edc6-8c0a-43f9-b046-b7755d991abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mod = pd.DataFrame({'date': pd.date_range(start='1/1/2023', freq='1d', periods=365)})\n",
    "df_mod.loc[:,'Bruttoleistung'] = pd.DataFrame(df_mod_raw.groupby(['Inbetriebnahme'], as_index=False)['Bruttoleistung'].sum()).iloc[:,1]\n",
    "df_mod.loc[:,'Nettonennleistung'] = pd.DataFrame(df_mod_raw.groupby(['Inbetriebnahme'], as_index=False)['Nettonennleistung'].sum()).iloc[:,1]\n",
    "df_mod.loc[:,'Bruttoleistung_kumulativ'] = df_mod.loc[:,'Bruttoleistung'].cumsum()+18643291\n",
    "df_mod.loc[:,'Nettonennleistung_kumulativ'] = df_mod.loc[:,'Nettonennleistung'].cumsum()+17044680\n",
    "df = df.merge(df_mod,on='date')\n",
    "# netto vor 2023: 17.044.680 kW\n",
    "# brutto vor 2023: 18.643.291 kW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f38cab3-b974-44bf-befe-0283996598fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_final_raw_2015_2023.csv',index_col='Unnamed: 0',parse_dates=['date'])\n",
    "\n",
    "cols_sd =['03668_SD_STRAHL',\n",
    "        '05792_SD_STRAHL',\n",
    "       '05856_SD_STRAHL',\n",
    "       '05705_SD_STRAHL',\n",
    "       '02290_SD_STRAHL',\n",
    "       '05404_SD_STRAHL']\n",
    "for col in cols_sd:\n",
    "    df.loc[(df.loc[:,col] < 0),col] = pd.NA\n",
    "\n",
    "cols_fd_fg =['03668_FD_STRAHL', '03668_FG_STRAHL', \n",
    "       '05792_FD_STRAHL', '05792_FG_STRAHL', \n",
    "       '05856_FD_STRAHL', '05856_FG_STRAHL', \n",
    "       '05705_FD_STRAHL', '05705_FG_STRAHL', \n",
    "       '02290_FD_STRAHL', '02290_FG_STRAHL', \n",
    "       '05404_FD_STRAHL', '05404_FG_STRAHL']\n",
    "for col in cols_fd_fg:\n",
    "    df.loc[(df.loc[:,col] < 1),col] = pd.NA\n",
    "\n",
    "# netto vor 2015: 10.135.888 kW \n",
    "# brutto vor 2015: 10.941.816 kW\n",
    "df.loc[:,'Bruttoleistung_kumulativ'] = df.loc[:,'Bruttoleistung'].cumsum()+10941816\n",
    "df.loc[:,'Nettoleistung_kumulativ'] = df.loc[:,'Nettoleistung'].cumsum()+10135888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edc0cda-5235-4521-96c9-7897c9aaf231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='date',y='05792_FD_STRAHL',figsize=(10,6)) #with NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb54a4d-4150-4864-b40a-5e36f76a95c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "r, c = np.where(df.iloc[:,:-4].isna())\n",
    "for i in range(len(r)):\n",
    "    cols_na = [col for col in df.columns if col.endswith(str(df.columns[c[i]])[5:])]\n",
    "    med_col = df.loc[(df['date'].dt.day==(df.iloc[r[i],0].day)) & (df['date'].dt.month==(df.iloc[r[i],0].month)),df.columns[c[i]]].median()\n",
    "    \n",
    "    med_row = df.loc[(df.index==r[i]) & (df['date'].dt.day==(df.iloc[r[i],0].day)) & (df['date'].dt.month==(df.iloc[r[i],0].month)),cols_na].sum().median()\n",
    "    mean_v = np.nanmean(np.array([med_col,med_row]))\n",
    "    df.iloc[r[i],c[i]] =mean_v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48542ad7-f2a5-4393-b867-b1575e7db156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='date',y='05792_FD_STRAHL',figsize=(10,6)) #with imputed values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356db451-6507-4492-8e2a-61b6e6458643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('us_df_final_2015_2023.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c94b14-06c5-4a89-b646-eb164e53f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='date',y='Act_in_MW',figsize=(10,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5d7afc-70a0-476f-ad43-2c076316b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x='date',y='Bruttoleistung_kumulativ',figsize=(10,6)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c874966-4d28-406b-a19c-d9a34448ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "stationen = ['Nürnberg',\n",
    "        'Zugspitze',\n",
    "       'Fürstenzell',\n",
    "       'Würzburg',\n",
    "       'Hohenpeißenberg',\n",
    "       'Weihenstephan-Dürnast']\n",
    "\n",
    "url = 'https://kachelmannwetter.com/de/vorhersage/2805615-wuerzburg/kompakt1x1'\n",
    "# url https://www.wetterkontor.de/wetter-vorhersage/deutschland/wuerzburg\n",
    "req = requests.get(url)\n",
    "req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c585d27-1a0f-4017-bab6-eec71c4a21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('CSV/us_df_final_2015_2023.csv',index_col='Unnamed: 0',parse_dates=['date'])\n",
    "df.loc[:,'Month'] = df.loc[:,'date'].dt.month\n",
    "df.loc[:,'Year'] = df.loc[:,'date'].dt.year\n",
    "df.loc[:,'Calendar_Week'] = df.loc[:,'date'].dt.strftime('%U')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85014540-894a-4987-850b-338ebf2b188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "ts_cv = TimeSeriesSplit(\n",
    "    n_splits=3,\n",
    "    gap=365,\n",
    "    max_train_size=10000,\n",
    "    test_size=500,\n",
    ")\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import  StandardScaler,OneHotEncoder\n",
    "\n",
    "def evaluate(model, X, y, cv, model_prop=None, model_step=None):\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring=[\"neg_mean_absolute_error\", \"neg_root_mean_squared_error\",\"r2\"],\n",
    "        return_estimator=model_prop is not None,\n",
    "        error_score='raise'\n",
    "    )\n",
    "    if model_prop is not None:\n",
    "        if model_step is not None:\n",
    "            values = [\n",
    "                getattr(m[model_step], model_prop) for m in cv_results[\"estimator\"]\n",
    "            ]\n",
    "        else:\n",
    "            values = [getattr(m, model_prop) for m in cv_results[\"estimator\"]]\n",
    "        print(f\"Mean model.{model_prop} = {np.mean(values)}\")\n",
    "    mae = -cv_results[\"test_neg_mean_absolute_error\"]\n",
    "    rmse = -cv_results[\"test_neg_root_mean_squared_error\"]\n",
    "    r2 = cv_results[\"test_r2\"]\n",
    "    print(\n",
    "        f\"Mean Absolute Error:       {mae.mean():.3f} +/- {mae.std():.3f}\\n\"\n",
    "        f\"Coefficiant of Variation:  {(mae.std()/mae.mean()*100):.2f} %\\n\"\n",
    "        f\"R2 Score:                  {r2.mean():.2f} \\n\"\n",
    "        f\"Root Mean Squared Error:   {rmse.mean():.3f} +/- {rmse.std():.3f}\"\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d3e31d-ea98-497e-993a-c1746c74f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['03668_FD_STRAHL','03668_FG_STRAHL','03668_SD_STRAHL',\n",
    "    '05792_FD_STRAHL','05792_FG_STRAHL','05792_SD_STRAHL',\n",
    "    '05856_FD_STRAHL','05856_FG_STRAHL','05856_SD_STRAHL',\n",
    "    '05705_FD_STRAHL','05705_FG_STRAHL','05705_SD_STRAHL',\n",
    "    '02290_FD_STRAHL','02290_FG_STRAHL','02290_SD_STRAHL',\n",
    "    '05404_FD_STRAHL','05404_FG_STRAHL','05404_SD_STRAHL',\n",
    "    'Bruttoleistung_kumulativ','Nettoleistung_kumulativ','Month','Year']]\n",
    "y = df['Act_in_MW']\n",
    "for col in ['Month','Year']:\n",
    "    X[col] = X[col].astype(\"category\")\n",
    "categorical_columns = np.array(X.columns[X.dtypes == \"category\"])\n",
    "\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "gbr_t = HistGradientBoostingRegressor(random_state=42)\n",
    "\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "one_hot_gbrt_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", one_hot_encoder, categorical_columns)\n",
    "        ],\n",
    "        remainder=StandardScaler(),\n",
    "    ),\n",
    "    gbr_t,\n",
    ")\n",
    "\n",
    "evaluate(one_hot_gbrt_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20b53c-4e57-4d48-b612-ce2396f8bf9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = HistGradientBoostingRegressor(categorical_features=categorical_columns,random_state=42)\n",
    "evaluate(gbrt, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddefb4a1-a799-42cf-bcca-f6dc62a2cf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "X = df[['03668_FD_STRAHL','03668_FG_STRAHL','03668_SD_STRAHL',\n",
    "    '05792_FD_STRAHL','05792_FG_STRAHL','05792_SD_STRAHL',\n",
    "    '05856_FD_STRAHL','05856_FG_STRAHL','05856_SD_STRAHL',\n",
    "    '05705_FD_STRAHL','05705_FG_STRAHL','05705_SD_STRAHL',\n",
    "    '02290_FD_STRAHL','02290_FG_STRAHL','02290_SD_STRAHL',\n",
    "    '05404_FD_STRAHL','05404_FG_STRAHL','05404_SD_STRAHL',\n",
    "    'Bruttoleistung_kumulativ','Nettoleistung_kumulativ','Calendar_Week','Month','Year']]\n",
    "\n",
    "for col in ['Calendar_Week','Month','Year']:\n",
    "    X[col] = X[col].astype(\"category\")\n",
    "\n",
    "categorical_columns = np.array(X.columns[X.dtypes == \"category\"])\n",
    "\n",
    "alphas = np.logspace(-10, 10, 25)\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "one_hot_poly_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", one_hot_encoder, categorical_columns)\n",
    "        ],\n",
    "        remainder=StandardScaler(),\n",
    "    ),\n",
    "    Nystroem(kernel=\"rbf\", degree=3, n_components=300, random_state=42),\n",
    "    RidgeCV(alphas=alphas),\n",
    ")\n",
    "\n",
    "evaluate(one_hot_poly_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957ff72-37e4-46e9-8de5-c2526edfb93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = df[['03668_FD_STRAHL','03668_FG_STRAHL','03668_SD_STRAHL',\n",
    "    '05792_FD_STRAHL','05792_FG_STRAHL','05792_SD_STRAHL',\n",
    "    '05856_FD_STRAHL','05856_FG_STRAHL','05856_SD_STRAHL',\n",
    "    '05705_FD_STRAHL','05705_FG_STRAHL','05705_SD_STRAHL',\n",
    "    '02290_FD_STRAHL','02290_FG_STRAHL','02290_SD_STRAHL',\n",
    "    '05404_FD_STRAHL','05404_FG_STRAHL','05404_SD_STRAHL',\n",
    "    'Bruttoleistung_kumulativ','Nettoleistung_kumulativ','Calendar_Week','Month','Year']]\n",
    "\n",
    "for col in ['Calendar_Week','Month','Year']:\n",
    "    X[col] = X[col].astype(\"category\")\n",
    "\n",
    "categorical_columns = np.array(X.columns[X.dtypes == \"category\"])\n",
    "\n",
    "alphas = np.logspace(-10, 10, 25)\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "rf_reg_pipeline = make_pipeline(\n",
    "    ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"categorical\", one_hot_encoder, categorical_columns)\n",
    "        ],\n",
    "        remainder=StandardScaler(),\n",
    "    ),\n",
    "    RandomForestRegressor(n_estimators=100,random_state=42),\n",
    ")\n",
    "\n",
    "evaluate(rf_reg_pipeline, X, y, cv=ts_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a880e13d-8bce-43e0-8578-b7cb8e19e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = list(ts_cv.split(X, y))\n",
    "train_0, test_0 = all_splits[0]\n",
    "train_1, test_1 = all_splits[1]\n",
    "train_2, test_2 = all_splits[2]\n",
    "\n",
    "gbrt.fit(X.iloc[train_0], y.iloc[train_0])\n",
    "gbrt_pred = gbrt.predict(X)\n",
    "\n",
    "one_hot_gbrt_pipeline.fit(X.iloc[train_0], y.iloc[train_0])\n",
    "gbrt_predictions = one_hot_gbrt_pipeline.predict(X.iloc[test_0])\n",
    "\n",
    "one_hot_poly_pipeline.fit(X.iloc[train_1], y.iloc[train_1])\n",
    "one_hot_poly_predictions = one_hot_poly_pipeline.predict(X)\n",
    "\n",
    "rf_reg_pipeline.fit(X.iloc[train_2], y.iloc[train_2])\n",
    "rf_reg_predictions = rf_reg_pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b2900f-a678-4223-906e-4bfb3a0b8281",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_months = slice(365)\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "fig.suptitle(\"Predictions by non-linear regression models\")\n",
    "ax.plot(\n",
    "    y.values,\n",
    "    \"x-\",\n",
    "    alpha=0.2,\n",
    "    label=\"Actual produced\",\n",
    "    color=\"black\",\n",
    ")\n",
    "#ax.plot(\n",
    "#    gbrt_pred,\n",
    "#    \"x-\",\n",
    "#    alpha=0.5,\n",
    "#    label=\"Gradient Boosted Trees\",\n",
    "#)\n",
    "#ax.plot(\n",
    "#    gbrt_predictions[last_months],\n",
    "#    \"x-\",\n",
    "#    label=\"One-hot + StdScaler + Gradient Boosted Trees\",\n",
    "#)\n",
    "ax.plot(\n",
    "    one_hot_poly_predictions,\n",
    "    \"x-\",\n",
    "    alpha=0.5,\n",
    "    label=\"One-hot + rbf kernel\",\n",
    ")\n",
    "ax.plot(\n",
    "    rf_reg_predictions,\n",
    "    \"x-\",\n",
    "    alpha=0.5,\n",
    "    label=\"Random Forest Regressor\",\n",
    ")\n",
    "_ = ax.legend()\n",
    "#_ = ax.set_xticks(ticks=(list(range(0,180,25))),labels=df.loc[slice(50,230,25),'date'])\n",
    "#_ = ax.tick_params(axis='x',labelrotation=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da832cca-9b2d-4987-9563-e59cc54f3afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(X.corr().abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df833395-5a39-4e43-8ecb-ecb353d1f130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install prophet\n",
    "from prophet import Prophet\n",
    "import prophet\n",
    "import Cython \n",
    "import cmdstanpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fa931-deef-4066-b364-fb24bdf47c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = df.loc[:,['date','Act_in_MW']]\n",
    "df_p.columns = ['ds','y']\n",
    "df_p.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0dee8c-fd1f-4ed5-9995-3e0d1e6f83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Prophet()\n",
    "m.fit(df_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb4fbc-7085-4bd3-955c-aa4637048a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(periods=365)\n",
    "future.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11614092-7133-43d7-9b75-c2b3d5ea937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = m.predict(future)\n",
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5c958-bea2-46f0-b62f-f58719df5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "fig.suptitle(\"Predictions by Prophet\")\n",
    "ax.plot(\n",
    "    df.loc[:,'Act_in_MW'],\n",
    "    \"x-\",\n",
    "    label=\"Actual produced\",\n",
    "    color=\"black\",\n",
    ")\n",
    "ax.plot(\n",
    "    forecast['yhat'],\n",
    "    \"x-\",\n",
    "    label=\"Prophet\",\n",
    ")\n",
    "_ = ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15b33b-6840-4438-b125-5a1e80ffabf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "\n",
    "plot_plotly(m, forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1460400b-91a6-42c4-b125-aaa688503236",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
