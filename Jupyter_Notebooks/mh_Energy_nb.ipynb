{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8540f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d22ebb",
   "metadata": {},
   "source": [
    "# Marktstammdatenregisters\n",
    "\n",
    "### Read data and combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0aa6f",
   "metadata": {},
   "source": [
    "\n",
    "# Applied mask, grouped by Inbetriebnahmedatum and sum of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56c6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_combine_files(start, end, folder_path):\n",
    "    # Liste zum Speichern der eingelesenen DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Durchlaufe den Bereich der Nummern\n",
    "    for i in range(start, end + 1, 5000):\n",
    "        # Erstelle den Dateinamen basierend auf dem Nummernbereich\n",
    "        file_name = f\"Stromerzeuger_{i}_bis_{i + 4999}.csv\" \n",
    "\n",
    "        # Erstelle den vollständigen Pfad zur CSV-Datei\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Lese das CSV in einen DataFrame ein und füge ihn zur Liste hinzu\n",
    "        df = pd.read_csv(file_path, delimiter=';')\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Lese die letzte Datei ein\n",
    "    last_file_path = os.path.join(folder_path, 'Stromerzeuger_465001_bis_465169.csv')\n",
    "    last_df = pd.read_csv(last_file_path, delimiter=';')\n",
    "\n",
    "    # Füge die letzte Datei zum DataFrame hinzu\n",
    "    dfs.append(last_df)\n",
    "\n",
    "    # Kombiniere alle DataFrames nach dem Index\n",
    "    combined_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "folder_path = r'C:\\Users\\mohdr\\Portfolio project\\Marktstammdatenregister'\n",
    "\n",
    "combined_df = read_and_combine_files(1, 464999, folder_path)\n",
    "\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4009f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selected_bruttoleistung = combined_df.groupby('Inbetriebnahmedatum der Einheit')['Bruttoleistung der Einheit'].apply(lambda x: x.str.replace(',', '.').astype(float).sum())\n",
    "\n",
    "#print(selected_bruttoleistung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0686ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame mit Datum erstellen\n",
    "df_combined = pd.DataFrame({'date': pd.date_range(start='1/1/2015', end='12/31/2023', freq='1d')})\n",
    "\n",
    "# Nur die Zeilen filtern, die den 'Betriebs-Status' 'In Betrieb' haben\n",
    "mask_combined_df = (combined_df['Betriebs-Status'] == 'In Betrieb')\n",
    "df_combined_filtered = combined_df.loc[mask_combined_df, :].copy()  # Kopie erstellen\n",
    "\n",
    "# 'Inbetriebnahmedatum der Einheit' in Datumstyp konvertieren\n",
    "df_combined_filtered['Inbetriebnahmedatum der Einheit'] = pd.to_datetime(df_combined_filtered['Inbetriebnahmedatum der Einheit'], format=\"%d.%m.%Y\", errors='coerce')\n",
    "\n",
    "# Gruppensummen für 'Bruttoleistung der Einheit' und 'Nettonennleistung der Einheit' basierend auf 'Inbetriebnahmedatum der Einheit' berechnen\n",
    "grouped_sum = df_combined_filtered.groupby('Inbetriebnahmedatum der Einheit').agg({\n",
    "    'Bruttoleistung der Einheit': lambda x: x.str.replace(',', '.').astype(float).sum(),\n",
    "    'Nettonennleistung der Einheit': lambda x: x.str.replace(',', '.').astype(float).sum()\n",
    "}).reset_index()\n",
    "\n",
    "# Spaltennamen ändern\n",
    "grouped_sum = grouped_sum.rename(columns={'Bruttoleistung der Einheit': 'Bruttoleistung', 'Nettonennleistung der Einheit': 'Nettoleistung'})\n",
    "\n",
    "# Gruppensummen in den DataFrame df_combined einfügen\n",
    "df_combined = df_combined.merge(grouped_sum, left_on='date', right_on='Inbetriebnahmedatum der Einheit', how='left').fillna(0)\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "df_combined = df_combined.drop(columns=['Inbetriebnahmedatum der Einheit'])  # Optional: Entfernen Sie die zusätzliche Spalte\n",
    "print(df_combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67644932",
   "metadata": {},
   "source": [
    "# Bayern\n",
    "### Tatsächliche und prognostizierte Solarenergieeinspeisung in der Regelzone von TenneT Deutschland - Bayern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ff1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source: https://netztransparenz.tennet.eu/de/strommarkt/transparenz/transparenz-deutschland/netzkennzahlen/tatsaechliche-und-prognostizierte-solarenergieeinspeisung/bayern/\n",
    "# filtered for 2023-01-01 to 2023-12-31\n",
    "\n",
    "df_en_raw = pd.read_table('solarEnergyFeedIn_BY_2015-01-01_2023-12-31.csv',sep=';',parse_dates=['Datum'],decimal=',')\n",
    "\n",
    "df_en = pd.DataFrame({'date': pd.date_range(start='1/1/2015', end='12/31/2023', freq='1d')})\n",
    "\n",
    "df_en.loc[:,'Prog_in_MW'] = pd.DataFrame(df_en_raw.groupby(['Datum'], as_index=False)['Prognostiziert in MW'].sum()).iloc[:,1]\n",
    "df_en.loc[:,'Act_in_MW'] = pd.DataFrame(df_en_raw.groupby(['Datum'], as_index=False)['Tatsaechlich in MW'].sum()).iloc[:,1]\n",
    "\n",
    "#df = df.merge(df_en,on='date')\n",
    "#df_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028edb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en_comb = pd.merge(df_combined,df_en, on = 'date')\n",
    "df_en_comb = pd.DataFrame(df_en_comb)\n",
    "print(df_en_comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14938c8a",
   "metadata": {},
   "source": [
    "# Stationsmessungen der Solarstrahlung\n",
    "\n",
    "tageswerte_ST_03668, 05792, 05856, 05705 und 02290 \\\\\n",
    "07370 und 00867 Started 2021 and 05404 Ended 2014, therefore these stations are excluded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9da71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stations = pd.DataFrame({'date': pd.date_range(start='1/1/2015', end='31/12/2023', freq='1d')})\n",
    "#'07370' Started 2021, '05404' Ended 2014 and '00867 Started 2021', therefore these stations are excluded\n",
    "\n",
    "stationsid = ['03668', '05792', '05856', '05705', '02290', '05404']\n",
    "\n",
    "for id in stationsid:\n",
    "    stationsname = f'stationid_{id}.txt'\n",
    "    \n",
    "    # Construct the full path to the station file within the 'Station' folder\n",
    "    station_path = os.path.abspath(os.path.join(os.getcwd(), 'Stations', stationsname))\n",
    "    \n",
    "    df_stat = pd.read_csv(station_path, sep=';', parse_dates=['MESS_DATUM'], usecols=['MESS_DATUM', 'FD_STRAHL', 'FG_STRAHL', 'SD_STRAHL'])\n",
    "    \n",
    "    mask = (df_stat['MESS_DATUM'] >= '2015-01-01') & (df_stat['MESS_DATUM'] <= '2023-12-31')\n",
    "    \n",
    "    df_stat.columns = ['date', f'{id}_FD_STRAHL', f'{id}_FG_STRAHL', f'{id}_SD_STRAHL']\n",
    "    \n",
    "    # Merge based on the 'date' column\n",
    "    df_stations = df_stations.merge(df_stat.loc[mask, :], on='date')\n",
    "df_stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d797d7",
   "metadata": {},
   "source": [
    "# Final Combination DataFrame from 3 Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adecbbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final = df_stations.merge(df_en_comb, on = 'date')\n",
    "df_final.head()\n",
    "#df_final.to_csv('df_final_raw_2015_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('us_df_final_2015_2023.csv', index_col=0)\n",
    "\n",
    "# Annahme: df ist dein DataFrame mit den Zeitreihen-Daten\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "# Angenommen, deine Daten sind bereits eingelesen\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df.index.freq = 'D'  # Hier die entsprechende Frequenz einfügen\n",
    "\n",
    "df['Act_in_MW'].plot(figsize=(12, 6), title='Stromproduktion')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
