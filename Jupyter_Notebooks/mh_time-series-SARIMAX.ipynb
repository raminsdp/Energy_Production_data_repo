{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b717fb0-0145-40e7-95bf-06dfb89a04d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2401c2-2b06-488d-a4a9-60b0fb28543c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "df = pd.read_csv(r'C:\\Users\\mohdr\\Portfolio project\\CSV\\us_df_final_2015_2023.csv', index_col = 0)\n",
    "df.set_index('date', inplace=True)\n",
    "# df.info()  # Falls du Informationen über den DataFrame anzeigen möchtest\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c5238e-44aa-4937-bace-60afde9cdd42",
   "metadata": {},
   "source": [
    "### Downsample to weekly frequency by summing the daily values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541f79a-35bf-4300-9536-208ee7d34eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to DatetimeIndex\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "# Downsample to weekly frequency by summing the daily values\n",
    "df_weekly = df.resample('W').sum()\n",
    "#df_weekly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735b13b",
   "metadata": {},
   "source": [
    "# Step 1: Check for stationarity of time series\n",
    "## Method #1: time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72afdc6d-63d8-4f4b-93e9-f4ad2848c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Act_in_MW column is assuming\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_weekly.index, df_weekly['Act_in_MW'])\n",
    "plt.title('Actual_energy_erzeugung_in_MW')\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6577c0-0f37-4b9e-8bec-460edf996725",
   "metadata": {},
   "source": [
    "## Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089af96b-bc4d-4c56-9362-f40dd38fdb0c",
   "metadata": {},
   "source": [
    "### Act_in_MW' is the column want to decompose\n",
    "Decomposing the Act_in_MW feature helps identify its trend, seasonal patterns, and noise. This breakdown aids in understanding its behavior over time, improving forecasting accuracy and revealing underlying patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b010c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(df_weekly['Act_in_MW'], period=52)  \n",
    "\n",
    "# Plot the decomposed components\n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()  \n",
    "plt.show()\n",
    "#fig.savefig('fig.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trend = decomposition.trend\n",
    "seasonal = decomposition.seasonal \n",
    "residual = decomposition.resid "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f65911",
   "metadata": {},
   "source": [
    "# Method #2: ADF Stationarity test \n",
    "The Augmented Dickey-Fuller (ADF) test is crucial for time series analysis as it determines whether a series is stationary or not. Stationarity is a fundamental assumption for many time series models, including ARIMA. By conducting the ADF test, we can assess the stationarity of the data, which is essential for making accurate predictions and ensuring the reliability of statistical inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7daa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def test_stationarity(timeseries):\n",
    "    # Determing rolling statistics\n",
    "    rolmean = timeseries.rolling(window=52).mean()\n",
    "    rolstd = timeseries.rolling(window=52).std()\n",
    "\n",
    "    # Plot rolling statistics\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    orig = plt.plot(timeseries, color='blue', label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label='Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "\n",
    "    # Perform Dickey-Fuller test\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)' % key] = value\n",
    "    print(dfoutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispielaufruf mit der Spalte 'Act_in_MW'\n",
    "test_stationarity(df_weekly['Act_in_MW'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d487bc-7507-41fe-a291-83be214dbbf2",
   "metadata": {},
   "source": [
    "### The Dickey-Fuller Test resulte\n",
    "The Dickey-Fuller Test resulted in a test statistic of -8.080309e+00 and a very low p-value of 1.467470e-12, indicating strong evidence against the null hypothesis of non-stationarity. Therefore, we conclude that the time series is stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e08a9",
   "metadata": {},
   "source": [
    "# Transform to stationary: differencing\n",
    "Differencing may not be necessary since the data is already stationary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5fb739-8e6a-42ab-b23a-cbcba8460c40",
   "metadata": {},
   "source": [
    "### Understanding Differencing in Time Series Analysis\n",
    "Differencing involves subtracting each observation from its previous observation in a time series dataset. This process helps stabilize the mean of the series by removing trends or seasonal patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76dda01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly['first_difference'] = df['Act_in_MW'] - df_weekly['Act_in_MW'].shift(1)\n",
    "test_stationarity(df_weekly['first_difference'].dropna(inplace = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901d53c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: Berechnung der ersten Differenz\n",
    "df_weekly['first_difference'] = df_weekly['Act_in_MW'].diff()\n",
    "\n",
    "# Beispiel: Berechnung der saisonalen Differenz\n",
    "df_weekly['seasonal_first_difference'] = df_weekly['first_difference'] - df_weekly['first_difference'].shift(52)\n",
    "\n",
    "# Test auf Stationarität\n",
    "test_stationarity(df_weekly['seasonal_first_difference'].dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3237e1d",
   "metadata": {},
   "source": [
    "# Step 2: Determine ARIMA models parameters p,d, q and seasonal_pdq\n",
    "### Method #1: ACF plot and PACF plot\n",
    "\n",
    "These plots provide insights into the autocorrelation and partial autocorrelation structures of the time series data, which are crucial for selecting the appropriate parameters for the SARIMAX model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31a5e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax1 = fig.add_subplot(211)\n",
    "fig = sm.graphics.tsa.plot_acf(df_weekly.Act_in_MW.iloc[53:], lags=20, ax=ax1)\n",
    "ax2 = fig.add_subplot(212)\n",
    "fig = sm.graphics.tsa.plot_pacf(df_weekly.Act_in_MW.iloc[53:], lags=20, ax=ax2)\n",
    "#fig.savefig('ACF_PACF.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b6718-4fc4-4fa2-b332-18b348760b78",
   "metadata": {},
   "source": [
    "### Method #2: To determine the best parameter, cross-validation is applied\n",
    "Cross-validation in time series involves iteratively partitioning data into training and validation sets to evaluate model performance while preserving the temporal order of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a395310-853d-412d-a45e-267f246c9dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import warnings\n",
    "\n",
    "# Filter out the warning\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Parameterkombinationen für die Grid-Suche\n",
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "seasonal_pdq = [(x[0], x[1], x[2], 52) for x in pdq]  # Wochenliche saisonale Komponente\n",
    "\n",
    "best_aic = float(\"inf\")\n",
    "best_pdq = None\n",
    "best_seasonal_pdq = None\n",
    "\n",
    "# Initialisierung des Kreuzvalidierungssplitters\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Durchführung der Kreuzvalidierung\n",
    "for train_index, test_index in tscv.split(df_weekly):\n",
    "    train_data = df_weekly.iloc[train_index]\n",
    "    test_data = df_weekly.iloc[test_index]\n",
    "\n",
    "    # Finden der besten Parameter mit den Trainingsdaten\n",
    "    for param in pdq:\n",
    "        for param_seasonal in seasonal_pdq:\n",
    "            try:\n",
    "                mod = sm.tsa.statespace.SARIMAX(train_data['Act_in_MW'], order=param, seasonal_order=param_seasonal, enforce_stationarity=True, enforce_invertibility=False)\n",
    "                results = mod.fit()\n",
    "                if results.aic < best_aic:\n",
    "                    best_aic = results.aic\n",
    "                    best_pdq = param\n",
    "                    best_seasonal_pdq = param_seasonal\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "\n",
    "# Ausgabe der besten Parameter und des niedrigsten AIC-Werts\n",
    "print('Beste Parameter (pdq, seasonal_pdq):', best_pdq, best_seasonal_pdq)\n",
    "print('Bestes AIC:', best_aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cf9743-831d-40ec-9d25-8499e7f9c69c",
   "metadata": {},
   "source": [
    "# Step 3: Fit the SARIMAX model\n",
    "Once you fit the SARIMAX model with the optimal parameters, focus on the model summary, diagnostics (like AIC and BIC), residual analysis, predictions, and forecasts. These outputs help assess the model's goodness of fit, performance, and parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f81bb7-07a9-4f5a-a9aa-b313e5ad2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modell mit den besten Parametern anpassen\n",
    "mod = sm.tsa.statespace.SARIMAX(df_weekly['Act_in_MW'], order=(1,1,1), seasonal_order=(1,1,0,52), enforce_stationarity=True, enforce_invertibility=False)\n",
    "results = mod.fit()\n",
    "\n",
    "# Vorhersagen auf den Daten machen\n",
    "pred = results.predict()\n",
    "\n",
    "# Fehlermetriken berechnen\n",
    "mae = np.mean(np.abs(pred - df_weekly['Act_in_MW']))\n",
    "mse = np.mean((pred - df_weekly['Act_in_MW'])**2)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print('Mean Absolute Error (MAE):', mae)\n",
    "print('Mean Squared Error (MSE):', mse)\n",
    "print('Root Mean Squared Error (RMSE):', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005abf9-8309-4049-83d6-95689b664b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.summary())\n",
    "\n",
    "# Speichern Sie die Zusammenfassung als Bild\n",
    "#plt.figure(figsize=(10, 6))\n",
    "#plt.text(0.1, 0.1, results.summary().as_text(), {'fontsize': 10}, fontproperties='monospace')  # Stellen Sie die Schriftgröße und den Textstil ein\n",
    "#plt.axis('off')  # Deaktivieren Sie die Achsen\n",
    "#plt.savefig('summary.png', bbox_inches='tight', dpi=300)  # Speichern Sie das Bild mit hoher Qualität"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eb26c4-5951-40f4-9277-eaff27c64eff",
   "metadata": {},
   "source": [
    "#### Compare the actual values with the forecast using a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887448ae-92ff-4f4d-b6db-4590e7ce473b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekly['forecast'] = results.predict(start = '2023-01-01', end= '2023-12-31', dynamic= False)  \n",
    "df_weekly[['Act_in_MW', 'forecast']].plot(figsize=(10, 6))\n",
    "plt.title('Actual vs Forecast Values', fontweight='bold', fontsize=16)\n",
    "#df_weekly['forecast']\n",
    "#plt.savefig('actual vs Forecast.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08405898-2dd9-4595-a39e-4f79e53deb04",
   "metadata": {},
   "source": [
    "### Compare the actual values with the forecast using a graph with CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280b265-a7db-44a0-8935-b0d6b816bd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generiere Vorhersagen mit Konfidenzintervallen\n",
    "pred = results.get_prediction(start='2023-01-01', end='2023-12-31', dynamic=False)\n",
    "pred_conf = pred.conf_int()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_weekly.index, df_weekly['Act_in_MW'], label='Actual')\n",
    "plt.plot(pred.predicted_mean.index, pred.predicted_mean, color='red', label='Forecast')\n",
    "plt.fill_between(pred_conf.index, pred_conf.iloc[:, 0], pred_conf.iloc[:, 1], color='pink')\n",
    "\n",
    "plt.title('Actual vs Forecast Values with 95% Confidence Interval')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "#plt.savefig('Actual vs Forecast Confidence.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278388e-7620-4a04-b385-4d6389bdb35e",
   "metadata": {},
   "source": [
    "# Step 4: Make time series predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb7666c-6c22-4c1d-84f6-3bdf1b001fcf",
   "metadata": {},
   "source": [
    "### Forecast future values (e.g., for next 52 steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7802bfba-453c-4444-9f34-7b72fa8c8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_steps = 52\n",
    "# Get forecast object\n",
    "forecast = results.get_forecast(steps=forecast_steps)\n",
    "\n",
    "# Extract forecasted values\n",
    "forecast_values = forecast.predicted_mean\n",
    "\n",
    "# Extract standard errors of forecasted values\n",
    "forecast_errors = forecast.se_mean\n",
    "\n",
    "# Define confidence levels\n",
    "alpha_95 = 0.05\n",
    "alpha_90 = 0.1\n",
    "\n",
    "# Calculate confidence intervals based on forecast errors\n",
    "conf_int_95 = [(val - 1.96 * err, val + 1.96 * err) for val, err in zip(forecast_values, forecast_errors)]\n",
    "conf_int_90 = [(val - 1.645 * err, val + 1.645 * err) for val, err in zip(forecast_values, forecast_errors)]\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df_weekly.index, df_weekly.Act_in_MW, label='Actual')\n",
    "plt.plot(forecast_values.index, forecast_values, label='Forecast', color='red')\n",
    "plt.fill_between(forecast_values.index, [x[0] for x in conf_int_95], [x[1] for x in conf_int_95], color='pink', alpha=0.8, label='95% CI')\n",
    "#plt.fill_between(forecast_values.index, [x[0] for x in conf_int_90], [x[1] for x in conf_int_90], color='orange', alpha=0.3, label='90% CI')\n",
    "plt.title('Actual vs Predicted Values with Confidence Intervals', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Values')\n",
    "plt.legend(loc='upper left')\n",
    "#plt.savefig('actualforcasteCI.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63e7545-7db6-4e11-a4b8-3b1853d2a788",
   "metadata": {},
   "source": [
    "# Step 5: Evaluate model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee115e0-59fb-4f25-adba-b4695be6a9d6",
   "metadata": {},
   "source": [
    "### Calculate residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a3310-0c99-4cfc-9675-3fa831f3f20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Berechnen Sie die Residuen\n",
    "residuals = results.resid\n",
    "\n",
    "# Plot der Residuen ab 2016\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot der Residuen\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(residuals)\n",
    "plt.title('Residuals')\n",
    "plt.xlabel('date')\n",
    "plt.ylabel('Residuen')\n",
    "\n",
    "# Dichtediagramm\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals.plot(kind='kde')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('residuals.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39959a9c-d9d8-4d6f-aa16-27777630ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "decomposition_re = seasonal_decompose(residuals)  \n",
    "\n",
    "# Plot the decomposed components\n",
    "fig = plt.figure()  \n",
    "fig = decomposition_re.plot()  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39812f-be1d-4abf-808f-d659ba658c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Plot der Autokorrelationsfunktion (ACF)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plot_acf(residuals, lags=40, ax=plt.gca())\n",
    "plt.title('Autokorrelationsfunktion (ACF) der Residuen')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Autokorrelation')\n",
    "plt.show()\n",
    "\n",
    "# Plot der partiellen Autokorrelationsfunktion (PACF)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plot_pacf(residuals, lags=40, ax=plt.gca())\n",
    "plt.title('Partielle Autokorrelationsfunktion (PACF) der Residuen')\n",
    "plt.xlabel('Lag')\n",
    "plt.ylabel('Partielle Autokorrelation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72663c6f-03d5-4622-b4bf-058f9abbb43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import probplot\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Berechnen der Residuen\n",
    "residuals = results.resid\n",
    "\n",
    "# Erstellen des Gitters\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Normal probability plot of residuals (Normalwahrscheinlichkeitsplot der Residuen)\n",
    "probplot(residuals, plot=axs[0, 0])\n",
    "axs[0, 0].set_title('Normal Probability Plot of Residuals', fontweight='bold', fontsize=16)\n",
    "axs[0, 0].set_xlabel('Theoretical Quantiles')\n",
    "axs[0, 0].set_ylabel('Sample Quantiles')\n",
    "\n",
    "# Residuals versus fitted values (Residuen versus angepasste Werte)\n",
    "pred = results.fittedvalues  # Assuming 'results' is the variable storing the model results\n",
    "axs[0, 1].scatter(pred, residuals, alpha=0.5)\n",
    "axs[0, 1].axhline(y=0, color='red', linestyle='--')\n",
    "axs[0, 1].set_title('Residuals versus Fitted Values', fontweight='bold', fontsize=16)\n",
    "axs[0, 1].set_xlabel('Fitted Values')\n",
    "axs[0, 1].set_ylabel('Residuals')\n",
    "\n",
    "# ACF/PACF plot of residuals (ACF/PACF-Plot der Residuen)\n",
    "plot_acf(residuals, lags=40, ax=axs[1, 0])\n",
    "plot_pacf(residuals, lags=40, ax=axs[1, 1])\n",
    "axs[1, 0].set_title('ACF Plot of Residuals', fontweight='bold', fontsize=16)\n",
    "axs[1, 1].set_title('PACF Plot of Residuals', fontweight='bold', fontsize=16)\n",
    "\n",
    "# Layout anpassen\n",
    "plt.tight_layout()\n",
    "\n",
    "# Speichern des Plots\n",
    "plt.savefig('combined_plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a54ee-2232-49bd-81b7-818778eba68d",
   "metadata": {},
   "source": [
    "# Shapiro-Wilk-Test auf Normalverteilung der Residuen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaffda1-10cd-4880-a726-dfcca06116fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Shapiro-Wilk-Test auf Normalverteilung der Residuen\n",
    "shapiro_test_stat, shapiro_p_value = stats.shapiro(residuals)\n",
    "print('Shapiro-Wilk-Test Statistik:', shapiro_test_stat)\n",
    "print('Shapiro-Wilk-Test p-Wert:', shapiro_p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1cc24d-781c-4ccf-b29f-ace399f6fa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Visual Diagnostics\n",
    "# Plot the residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(residuals)\n",
    "plt.title('Residuals over Time', fontweight='bold', fontsize=16)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Residuals')\n",
    "#plt.savefig('Residuals over Time.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
